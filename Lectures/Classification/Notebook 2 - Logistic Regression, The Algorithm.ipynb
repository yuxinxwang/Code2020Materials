{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Just when we thought we were done with regression, it pulls us back in!\n",
    "\n",
    "To get an idea of how this algorithm works we'll look at some phony classification data. In the next notebook you'll use logistic regression to build a cancer classifier.\n",
    "\n",
    "## What You'll Accomplish\n",
    "<ul>\n",
    "    <li>We'll introduce the logistic regression algorithm,</li>\n",
    "    <li>Talk about classification cutoffs,</li>\n",
    "    <li>Introduce additional classification performance measures,</li>\n",
    "    <li>Show how you can interpret logistic regression output.</li>\n",
    "</ul>\n",
    "\n",
    "## The Algorithm\n",
    "\n",
    "We'll be using logistic regression for binary classification, classification problems with only two classes typically coded as $0$ or $1$. Normally the class denoted as $1$ is something we want to identify, for example someone that has a disease or someone that qualifies for a loan. \n",
    "\n",
    "<i>Note that logistic regression can be adapted for more than two classes, but for now we'll only focus on two.</i>\n",
    "\n",
    "#### From Binary to Continuous\n",
    "Logistic regression is a form of regression algorithm. Remember that regression algorithms are usually used to predict continuous outcomes, but binary classification is in no way continuous. This is where logisitic regression is a little clever, instead of modeling the output class, it models the probability that a particular data point is an instance of class $1$.\n",
    "\n",
    "Let's dive in with some fake data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the randomly generated data\n",
    "data = np.loadtxt(\"random_binary.csv\",delimiter = \",\")\n",
    "X = data[:,0]\n",
    "y = data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a stratified test train split\n",
    "# Practice, write the code to do that in these two blocks\n",
    "# First import the package\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now split the data\n",
    "# Have 20% for testing\n",
    "# Set 614 as the random state\n",
    "# and stratify the split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,\n",
    "                                                 test_size = .2,\n",
    "                                                 random_state = 614,\n",
    "                                                 shuffle = True,\n",
    "                                                 stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training data\n",
    "plt.figure(figsize = (10,8))\n",
    "\n",
    "plt.scatter(X_train,y_train)\n",
    "plt.ylim((-.1,1.1))\n",
    "plt.xlabel(\"Feature\",fontsize = 16)\n",
    "plt.ylabel(\"Class\",fontsize = 16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get down to the idea behind logistic regression. While the $y$-axis of the above plot says Class we could just as easily label it the Probability the instance is $1$. In this case since we know the class of each data point in the training set, the probability can only be $0$ or $1$. Now suppose you have a new data point for which you only have the vector of predictors, $X$. We're interested in the probability that this data point has class $y=1$, call this probability $P(y=1|X) = p(X)$. $p(X)$ can take on all values in $[0,1]$, this is a continuous variable.\n",
    "\n",
    "The way we model the probability in logistic regression is with a sigmoidal curve, the general form looks like this:\n",
    "$$\n",
    "f(x) = \\frac{1}{1+e^{-x}}.\n",
    "$$\n",
    "A graph of the curve this function produces is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 10\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "plt.plot(np.arange(-x,x,.01),1/(1+np.exp(-np.arange(-x,x,.01))))\n",
    "\n",
    "\n",
    "plt.xlabel(\"x\",fontsize = 14)\n",
    "plt.ylabel(\"f(x)\",fontsize = 14)\n",
    "\n",
    "plt.title(\"A Sigmoidal Curve\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this function stays between $0$ and $1$. Also like our phony data data it transitions from class $0$, to class $1$ in a continuous manner. This is the function type we'd like to use as our model.\n",
    "\n",
    "The model that is used in logistic regression is:\n",
    "$$\n",
    "p(X) = \\frac{1}{1 + e^{-X\\beta}},\n",
    "$$\n",
    "where $\\beta = \\left(\\beta_0,\\beta_1,\\dots,\\beta_m\\right)^T$ is a column vector of coefficients, $X$ has been extended to include a column of ones, and by multiplication we mean the standard vector dot product.\n",
    "\n",
    "The model is fit using the statistical method of maximum likelihood estimators (for a derivation of the loss function see the homework on logistic regression).\n",
    "\n",
    "Let's see how to use `sklearn` to fit a logistic regression model to our phony data, then see how we can use it for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice \n",
    "\n",
    "You'll make and fit the Logistic Regression model below for our phony data.\n",
    "\n",
    "The procedure follows the standard `sklearn` pattern for fitting and predicting a model. If you need more help check out the docs, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the logistic regression method\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# Make a model instance here\n",
    "log_reg = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# Fit the model here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've fit the model to our training data, let's plot the model along with our train data, and see what we're talking about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot figure \n",
    "plt.figure(figsize = (10,8))\n",
    "\n",
    "# With classifications we have a new method\n",
    "# predict_proba which returns the probability\n",
    "# that an observation is a certain class.\n",
    "plt.plot(np.linspace(0,1,1000),\n",
    "            log_reg.predict_proba(np.linspace(-.5,1.5,1000).reshape(-1,1))[:,1],\n",
    "            'r--',linewidth=2.5,label = \"Model Fit\")\n",
    "plt.scatter(X_train,y_train,label = 'Training Data',alpha=.7)\n",
    "plt.legend(fontsize = 14,loc = 4)\n",
    "plt.xlabel(\"Feature\",fontsize = 16)\n",
    "plt.ylabel(\"p(X)\",fontsize=16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dotted red line shows how the logistic regression model fit on our training data changes the probability of being and instance of the $1$ class as we increase the value for our feature. \n",
    "\n",
    "### From Probabilities to Classifications\n",
    "\n",
    "How would you propose we turn probability output into classifications?\n",
    "\n",
    "\n",
    "The standard approach is to just choose a probability cutoff, for instance if $p(X) \\geq .5$ we classify the instance as $1$, otherwise we say it is a $0$. This is an example of a <i>decision boundary</i>, any point to the left of the boundary gets classified as a $0$, on the right a $1$. Decision boundaries are a big part of many classification algorithms, so this won't be the last time we see them.\n",
    "\n",
    "Let's see what our training accuracy is for a cutoff of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to calculate the accuracy for any cutoff, then choose your cutoff\n",
    "cutoff = \n",
    "\n",
    "# store the predicted probabilities\n",
    "y_prob = log_reg.predict_proba(X_train.reshape(-1,1))[:,1]\n",
    "\n",
    "# assign the value based on the cutoff\n",
    "y_train_pred = \n",
    "\n",
    "# print the accuracy\n",
    "# input the accuracy after \"is\",\n",
    "print(\"The accuracy for a cutoff of\",cutoff,\n",
    "      \"is\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot how the accuracy changes with the cutoff\n",
    "cutoffs = np.linspace(0,1,100)\n",
    "\n",
    "accs = []\n",
    "\n",
    "for cutoff in cutoffs:\n",
    "    y_prob = log_reg.predict_proba(X_train.reshape(-1,1))[:,1]\n",
    "    y = 1*(y_prob >= cutoff)\n",
    "    \n",
    "    accs.append(sum(y == y_train)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "\n",
    "plt.xlabel(\"Cutoff\",fontsize = 16)\n",
    "plt.ylabel(\"Accuracy\",fontsize = 16)\n",
    "\n",
    "plt.plot(cutoffs,accs,'.')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Practice\n",
    "\n",
    "### Accuracy Isn't Everything\n",
    "\n",
    "As we did with knn we could use cross validation to decide on the best cutoff based on the average accuracy over the splits. That may work for this toy set, but sometimes accuracy is a misleading measure. With our dataset about $45\\%$ of the data are $0$ and $55\\%$ are $1$. What if it was a more extreme split, say $90\\%$ in class $0$ and $10\\%$ in class $1$. In that instance we could build a $90\\%$ accurate classifier by just labeling everything as $0$. However, we didn't correctly identify any of the class $1$ objects. This would be awful, if for instance class $1$ represented a person that has a disease, for instance COVID19.\n",
    "\n",
    "So it may be important to look at some alternative performance measures.\n",
    "\n",
    "#### Now Things Start To Get Confusing\n",
    "\n",
    "Additional performance measures are derived from the confusion matrix, pictured below.\n",
    "\n",
    "<img src=\"conf_mat.jpg\" alt=\"Confusion Matrix Image\" style=\"width:400px;\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the diagonal of the box represents data points that were correctly predicted by the algorithm, the off-diagonal represents points that are incorrectly predicted by the algorithm. Contained within each box of the confusion matrix are counts of how the algorithm sorted. For instance, in the TP box would be the total number of correct positive (correctly classified as $1$) classifications the algorithm made.\n",
    "\n",
    "Two popular measures derived from the confusion matrix are the algorithm's <i>precision</i> and <i>recall</i>:\n",
    "\n",
    "$$\n",
    "\\text{precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}, \\text{ out of all points predicted to be class } 1, \\text{ what fraction were actually class } 1.\n",
    "$$\n",
    "$$\n",
    "\\text{recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}, \\text{ out of all the actual data points in class } 1 \\text{, what fraction did the algorithm correctly predict?}\n",
    "$$\n",
    "\n",
    "You can think of precision as how much you should trust the algorithm when it says something is class $1$. Recall estimates the probability that the algorithm correctly detects class $1$ data points.\n",
    "\n",
    "You've likely heard of these types of measures in all the news stories about COVID19 tests.\n",
    "\n",
    "Let's examine the training precision and recall for our algorithm if we use the $0.5$ cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the precision and recall here\n",
    "y_train_pred = 1*(y_prob >= 0.5)\n",
    "\n",
    "tp_train = np.sum(((y_train_pred == 1) & (y_train == 1)))\n",
    "fp_train = np.sum(((y_train_pred == 1) & (y_train == 0)))\n",
    "fn_train = np.sum(((y_train_pred == 0) & (y_train == 1)))\n",
    "tn_train = np.sum(((y_train_pred == 0) & (y_train == 0)))\n",
    "\n",
    "print(\"The precision is \" + str(np.round((tp_train/(tp_train + fp_train)),2)))\n",
    "print(\"The recall is \" + str(np.round((tp_train/(tp_train + fn_train)),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are pretty good. We should expect to be able to get decent recall and precision for this data set because it is well balanced between the two classes, and they are pretty well separated by the feature. In general classification algorithms have a precision-recall tradeoff, when you increase precision you tend to decrease recall and vice-versa. In the homework you'll examine this tradeoff.\n",
    "\n",
    "### The ROC Curve\n",
    "\n",
    "Another way to measure the performance of your classifier is the <i>receiver operating characteristic</i> (ROC) curve.\n",
    "\n",
    "This plots the <i>true positive rate</i> (tpr), i.e. the recall, vs the <i>false positive rate</i> (fpr). Returning to the confusion matrix the fpr is:\n",
    "$$\n",
    "\\text{fpr} = \\frac{\\text{FP}}{\\text{FP}+\\text{TN}} = 1 - \\frac{\\text{TN}}{\\text{FP} + \\text{TN}} = 1 - \\text{specificity},\n",
    "$$\n",
    "specifity is a term used a lot in public health and is another name for true negative rate. Public Health so hot right now.\n",
    "\n",
    "Let's plot an ROC curve for our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the function from sklearn\n",
    "# this function is very nice for making roc \n",
    "# curves\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fpr and tpr\n",
    "# you put in the training data\n",
    "# and the predicted probabilites\n",
    "# it returns the fpr, tpr, and corresponding\n",
    "# cutoffs\n",
    "fpr, tpr, cutoffs = roc_curve(y_train,y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the roc curve\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# plot the curve\n",
    "plt.plot(fpr,tpr,linewidth=2)\n",
    "\n",
    "# plot what you'd get with random guessing\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "\n",
    "plt.axis([-0.1,1,0,1.1])\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\",fontsize=16)\n",
    "plt.ylabel(\"True Positive Rate\",fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How was the ROC curve made? The `roc_curve` function went through and calculated the true and false positive rates that resulted from various cutoffs (these cutoffs are stored in `cutoffs` in the above code).\n",
    "\n",
    "#### AUC\n",
    "\n",
    "ROC curves come with an additional measure called AUC (area under the curve). An AUC of $1$ would be a perfect classifer, an AUC of $.5$ is what you'd get with random guessing. So what is a good AUC? well it's hard to say with a single classifier, but it can be used to compare multiple classifiers, for example if you're choosing between a classifier with AUC $.8$ and an AUC of $.85$ you'd go with the one that has AUC $.85$.\n",
    "\n",
    "Let's see how to calculate AUC with `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the function from sklearn\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put in the true classes along with the \n",
    "# probability scores.\n",
    "roc_auc_score(y_train,y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's dive back into logistic regression specific material.\n",
    "\n",
    "## Interpreting Logistic Regression\n",
    "\n",
    "One nice thing about this algorithm is that we can interpret the results. This is always a nice feature of an algorithm.\n",
    "\n",
    "Reconsider the statistical model that we fit:\n",
    "$$\n",
    "p(X) = \\frac{1}{1 + e^{- X \\beta}}.\n",
    "$$\n",
    "Rearranging this equation we find the following:\n",
    "$$\n",
    "\\log\\left(\\frac{p(X)}{1-p(X)}\\right) =  X \\beta.\n",
    "$$\n",
    "The expression $p(X)/(1-p(X))$ is known as the odds of the event $y=1$. So the statistical model for logistic regression is really just a linear model for the $\\log$ odds of being class $1$. This allows us to interpret the coefficients of our model.\n",
    "\n",
    "Look at the model we just fit:\n",
    "$$\n",
    "\\log\\left(\\frac{p(x)}{1-p(x)}\\right) = \\beta_0 + \\beta_1 x, \\text{ or } \\text{Odds}|x = C e^{\\beta_1 x}\n",
    "$$\n",
    "where $x$ is the feature, and $C$ is some constant we don't care about. \n",
    "\n",
    "So if we increase $x$ from say $d$ to $d+1$, a $1$ unit increase, then our odds are $e^{\\beta_1}$ units times larger (or smaller depending on the value of $\\beta_1$), we can see this below:\n",
    "$$\n",
    "\\frac{\\text{Odds}|x = d+1}{\\text{Odds}|x=d} = \\frac{e^{\\beta_1 (d+1)}}{e^{\\beta_1 d}} = e^{\\beta_1}\n",
    "$$\n",
    "\n",
    "Let's look at the coefficient from our phony data logistic regression and interpret it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A .1 unit increase in our feature multiplies\" + \n",
    "      \" the odds of being classified as 1 by \" + \n",
    "      str(np.round(np.exp(.1*log_reg.coef_[0][0]),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a nice feature because it allows us to better understand the algorithm, which in turn enables data scientists to communicate with their clients what the algorithm is actually doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before You Go\n",
    "\n",
    "While we were explaining the concept of logistic regression, we didn't mention any of the assumptions of the algorithm. Let's talk about that here before we move on to real data.\n",
    "<ol>\n",
    "    <li>Each sample must be independent from all other samples,</li>\n",
    "    <li>When using multiple predictors, they shouldn't be correlated,</li>\n",
    "    <li>The log odds depend linearly on the predictors,</li>\n",
    "    <li>Logistic regression should have a largish data set to work with.</li>\n",
    "</ol>\n",
    "\n",
    "We did not worry about these assumptions in this notebook because the data were randomly generated to fit these assumptions. However, in real world applications you should check them when deciding whether or not logistic regression is a good model choice. \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
