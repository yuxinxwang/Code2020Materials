{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Models\n",
    "\n",
    "In our final time series notebook we introduce the ARIMA model. We'll be limiting ourselves to non-seasonal models, but if you are interested in seasonal data we will give you references to learn about the seasonal model. We also go through an example of implementing ARIMA on seasonal data in the Time Series HW.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In particular this notebook goes over:\n",
    "<ul>\n",
    "    <li>Stationarity of time series data,</li>\n",
    "    <li>Differencing methods,</li>\n",
    "    <li>Autoregressive (AR) models,</li>\n",
    "    <li>Moving Average (MA) models,</li>\n",
    "    <li>AutoRegressive Integrated Moving Average (ARIMA) models.</li>\n",
    "</ul>\n",
    "\n",
    "As always we import the packages we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages we'll use\n",
    "from datetime import datetime\n",
    "\n",
    "## For data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity\n",
    "\n",
    "<i>Stationarity</i> is a property of time series data. In a nutshell it means that the statistical properties are constant over time. For example if we let $y|t$ be the value of our target at time $t$ stationarity implies:\n",
    "$$\n",
    "\\begin{array}{l l}\n",
    "E(y|t) = \\mu, & \\text{ some constant independent of } t\\\\\n",
    "\\text{cov}\\left(y|t, y|s\\right) = C(|t-s|), & \\text{ is a function that only depends on the time between } s \\text { and } t.\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "This automatically rules out seasonal and trending time series. \n",
    "\n",
    "\n",
    "Let's examine this plot and try to identify stationary time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and preparing data\n",
    "livestock = pd.read_csv(\"livestock.csv\", parse_dates = ['year'])\n",
    "goog = pd.read_csv(\"goog.csv\")\n",
    "gasoline = pd.read_csv(\"gasoline_2013.csv\")\n",
    "measles = pd.read_csv(\"measles.csv\",parse_dates = ['month'])\n",
    "elec = pd.read_csv(\"elec.csv\",parse_dates = ['month'])\n",
    "marathon = pd.read_csv(\"marathon.csv\",parse_dates = ['year'])\n",
    "lynx = pd.read_csv(\"lynx.csv\",parse_dates = ['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,3,figsize=(16,12))\n",
    "\n",
    "ax[0,0].plot(goog.closing_price)\n",
    "ax[0,0].set_xlabel(\"Day\")\n",
    "ax[0,0].set_ylabel(\"Closing Price\")\n",
    "\n",
    "ax[0,1].plot(goog.closing_price.diff())\n",
    "ax[0,1].set_xlabel(\"Day\")\n",
    "ax[0,1].set_ylabel(\"Closing Price Diff\")\n",
    "\n",
    "ax[0,2].plot(gasoline.barrels_m)\n",
    "ax[0,2].set_xlabel(\"Week\")\n",
    "ax[0,2].set_ylabel(\"Barrels Sold (mill)\")\n",
    "\n",
    "ax[1,0].plot(gasoline.barrels_m.diff())\n",
    "ax[1,0].set_xlabel(\"Week\")\n",
    "ax[1,0].set_ylabel(\"Barrels Sold (mill) Diff\")\n",
    "\n",
    "ax[1,1].plot(marathon.year,marathon.time)\n",
    "ax[1,1].set_xlabel(\"Year\")\n",
    "ax[1,1].set_ylabel(\"Winning Time\")\n",
    "\n",
    "ax[1,2].plot(lynx.year,lynx.captured)\n",
    "ax[1,2].set_xlabel(\"Year\")\n",
    "ax[1,2].set_ylabel(\"Lynx Captured\")\n",
    "\n",
    "ax[2,0].plot(measles.month,measles.cases)\n",
    "ax[2,0].set_xlabel(\"Date\")\n",
    "ax[2,0].set_ylabel(\"Cases of Measles\")\n",
    "\n",
    "ax[2,1].plot(elec.month,elec['production'])\n",
    "ax[2,1].set_xlabel(\"Date\")\n",
    "ax[2,1].set_ylabel(\"Electricity Produced\")\n",
    "\n",
    "ax[2,2].plot(livestock.year,livestock.million_head)\n",
    "ax[2,2].set_xlabel(\"Year\")\n",
    "ax[2,2].set_ylabel(\"Million Heads of Sheep\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data we can rule out any data with a trend, or seasonality.\n",
    "\n",
    "There are three plots that display a stationary time series. The two Diff plots, created by taking the pairwise differences of time series (more on this soon), and the plot of lynx captures in the second row of plots. \n",
    "\n",
    "The first two have no clear pattern, trend, or seasonality. The lynx plot may look seasonal at a glance, but upon closer inspection the cycles that are present are not at regular intervals, meaning the data is not seasonal. \n",
    "\n",
    "\n",
    "### Making a Time Series Stationary\n",
    "\n",
    "It is often desirable to take a non-stationary time series, for example the Google closing price data, and transform it into one that is stationary, like the Google differences data. \n",
    "\n",
    "#### Differencing\n",
    "\n",
    "As we've alluded to a main technique in creating stationary series is differencing. Take the time series, $y_t$, with $T$ observations and use it to create a new series like so:\n",
    "$$\n",
    "y_t - y_{t-1} = y_t'\n",
    "$$\n",
    "\n",
    "`pandas` has a great method for making the differenced time series, `.diff()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We'll get the differenced series here\n",
    "\n",
    "# diff computes row-wise differences\n",
    "goog.diff().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this new series, $y_t'$ only has $T-1$ observations.\n",
    "\n",
    "##### Checking with ACF Plots\n",
    "\n",
    "We can check to see how the trend and seasonality were affected by making some ACF plots.\n",
    "\n",
    "Below we'll plot the Google data plot in blue, and the differenced plot in red on top of the blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bring back functions from notebook 2\n",
    "\n",
    "\n",
    "def make_lag_df(df,feature,lag):\n",
    "    lag_df = df.copy()\n",
    "    lag_df[feature+\"_lag\"] = np.nan\n",
    "    \n",
    "    lag_df.loc[lag:,feature+\"_lag\"] = lag_df.loc[0:len(lag_df)-(lag+1),feature].values\n",
    "    \n",
    "    return lag_df\n",
    "\n",
    "\n",
    "def get_autocorr(df,feature,lag):\n",
    "    df = make_lag_df(df,feature,lag)\n",
    "    mean_y = df[feature].mean()\n",
    "    \n",
    "    y_ts = df[feature].values\n",
    "    y_lags = df.dropna()[feature+\"_lag\"].values\n",
    "    \n",
    "    numerator = np.sum((y_ts[lag:] - mean_y)*(y_lags - mean_y))\n",
    "    denom = np.sum(np.power(y_ts - mean_y,2))\n",
    "    \n",
    "    return numerator/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting block\n",
    "from matplotlib.lines import Line2D\n",
    "custom_lines = [Line2D([0], [0], color=\"blue\", lw=4),\n",
    "                Line2D([0], [0], color=\"red\", lw=4)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Google Data\n",
    "# we'll go up to 50 lag\n",
    "n=50\n",
    "\n",
    "# this stores the autocorrelations for the \n",
    "# google data\n",
    "goog_autos = []\n",
    "\n",
    "# get the autocorr.\n",
    "for i in range(1,n,1):\n",
    "    goog_autos.append(get_autocorr(goog,'closing_price',i))\n",
    "\n",
    "# make a figure\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# plot a horizontal line\n",
    "plt.axhline(y=0, xmin=0, xmax=n, color = \"blue\")\n",
    "\n",
    "# plot each autocorrelation against the lag\n",
    "plt.scatter(range(1,n,1), \n",
    "           goog_autos,\n",
    "           c='b')\n",
    "\n",
    "# Plot vertical lines\n",
    "for i in range(1,n,1):\n",
    "    plt.plot(i*np.ones(2),[0,goog_autos[i-1]],'b')\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel(\"Lag\", fontsize=16)\n",
    "plt.ylabel(\"ACF\", fontsize=16)\n",
    "\n",
    "# set tick marks\n",
    "plt.xticks(np.arange(1,n,1), fontsize=8)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "\n",
    "### Google Diff Data\n",
    "goog_diff_autos = []\n",
    "\n",
    "# get the autocorr for the diff data\n",
    "# this creates the differences\n",
    "# then drops the nas\n",
    "# then resets our index \n",
    "# we'll only use it for the autocorr calcs\n",
    "diff_data = goog.diff().dropna().reset_index(drop=True)\n",
    "\n",
    "for i in range(1,n,1):\n",
    "    goog_diff_autos.append(get_autocorr(diff_data,'closing_price',i))\n",
    "\n",
    "# plot each autocorrelation against the lag\n",
    "plt.scatter(range(1,n,1), \n",
    "           goog_diff_autos,\n",
    "           c='r')\n",
    "\n",
    "# Plot vertical lines\n",
    "for i in range(1,n,1):\n",
    "    plt.plot(i*np.ones(2),[0,goog_diff_autos[i-1]],'r')\n",
    "    \n",
    "plt.legend(custom_lines, ['Google Closing Price', 'Google Differenced'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the huge difference?\n",
    "\n",
    "Our differenced data has negligible autocorrelations, indicating no seasonality or trends.\n",
    "\n",
    "#### Second, Third, Fourth Difference and More\n",
    "\n",
    "Sometimes differencing isn't enough and you'll want to do it again. \n",
    "\n",
    "Occasionally the differenced data will not appear to be stationary and it may be necessary to difference the data a second time to obtain a stationary series.\n",
    "\n",
    "Let $y_t'$ be the differenced series. Then the second differenced series can be obtained like so:\n",
    "$$\n",
    "y_t' - y_{t-1}' = y_{t}'',\n",
    "$$\n",
    "or\n",
    "$$\n",
    "(y_t - y_{t-1}) - (y_{t-1} - y_{t-2}) = y_t - 2y_{t-1} - y_{t-2} = y_t''\n",
    "$$\n",
    "\n",
    "Which now has $T-2$ observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goog.diff().diff().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can continue in this way a third, fourth, fifth time or even more. Just be careful you aren't throwing away too much data in the process.\n",
    "\n",
    "##### Random Walk Models\n",
    "\n",
    "Consider again our single differences, $y_t - y_{t-1}$. Sometimes this difference can be modeled as draws from some random distribution. When this is the case we can denote the difference as $\\epsilon_t$,\n",
    "$$\n",
    "y_t - y_{t-1} = \\epsilon_t.\n",
    "$$\n",
    "\n",
    "We can then use this to derive a model for $y_t$ called a random walk model:\n",
    "$$\n",
    "y_t = y_{t-1} + \\epsilon_t.\n",
    "$$\n",
    "\n",
    "It's called a random walk because our next position is determined by our current position plus a random step. \n",
    "\n",
    "From <a href = \"https://otexts.com/fpp2/stationarity.html\">Forecasting: Principles and Practice</a>:\n",
    "<q>\n",
    "    Random walk models are widely used for non-stationary data, particularly financial and economic data.\n",
    "</q>\n",
    "\n",
    "These models should look quite familiar, think of the na\\&iuml;ve method from Notebook 1.\n",
    "\n",
    "## Practice\n",
    "\n",
    "You'll learn about the seasonal differencing technique using the measles data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pre 1963 measles data here\n",
    "# you don't need to load in the data\n",
    "# we've done that above and stored it in\n",
    "# measles\n",
    "measles_1963 = measles.loc[measles.month < datetime(1963,1,1),]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to perform differencing with seasonal data is to subtract off the corresponding observation from the previous season. \n",
    "\n",
    "So for example if a season is completed every $5$ time steps, then the differencing would be:\n",
    "$$\n",
    "y_t - y_{t-5} = y_t'.\n",
    "$$\n",
    "\n",
    "In general if a season is completed every $m$ time steps, then the differencing would be:\n",
    "$$\n",
    "y_t - y_{t-m} = y_t'\n",
    "$$.\n",
    "\n",
    "Recall that for the measles data, a season lasts $2$ years or $24$ months. Perform seasonal differencing on the pre 1963 measles data and plot it.\n",
    "\n",
    "Hint: here is the documentation for `.diff()`, <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.diff.html\">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.diff.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now introduce the two parts of an ARIMA Model before fitting one ourselves.\n",
    "\n",
    "## Autoregressive (AR) Models\n",
    "\n",
    "The AR in ARIMA comes from Autoregressive.\n",
    "\n",
    "This word should seem somewhat familiar, especially the regress part. Remember a regression model was one that used other features, $X$, to predict the target, $y$. In autoregressive models you regress the target on past observations of itself.\n",
    "\n",
    "An autoregressive model of order $p$, referred to as AR(p), takes the form:\n",
    "$$\n",
    "y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\dots + \\phi_p y_{t-p} + \\epsilon_t, \n",
    "$$\n",
    "where $\\epsilon_t$ is a random noise term.\n",
    "\n",
    "If:\n",
    "<ul>\n",
    "    <li>$\\phi_i = 0$ for all $i$ you have what is known as <i>white noise,</i></li>\n",
    "    <li>$\\phi_1 = 1$ and $c=0,\\phi_i=0$ for all $i\\neq 1$ you have the random walk model,</li>\n",
    "    <li>$\\phi_1 = 1$, $c\\neq0$, and $\\phi_i=0$ for all $i\\neq1$ you have the random walk with drift model.</li>\n",
    "</ul>\n",
    "\n",
    "We typically assume that the time series we're modeling with an AR model is stationary (which is why we introduced it above). This introduces restrictions on the parameters for AR models of any order. In particular for:\n",
    "<ul>\n",
    "    <li>AR(1), $-1 < \\phi_1 < 1$,</li>\n",
    "    <li>AR(2), $-1 < \\phi_2 < 1, \\ \\phi_1 + \\phi_2 < 1, \\ \\phi_2 - \\phi_1 < 1$.</li>\n",
    "</ul>\n",
    "\n",
    "We won't need to worry too much about the restrictions since we won't be coding by hand. The `statsmodels` package will handle them for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Average (MA) Models\n",
    "\n",
    "The MA in ARIMA comes from Moving Average.\n",
    "\n",
    "Moving average models are of a similar flavor to AR models, we still regress $y_t$ on past values, but this time not past values of the target data but past values of the forecast error. \n",
    "\n",
    "Here we present an order $q$ or MA($q$) model:\n",
    "$$\n",
    "y_t = c + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\dots + \\theta_q \\epsilon_{t-q},\n",
    "$$\n",
    "where $\\epsilon_t$ is random noise.\n",
    "\n",
    "As with AR models we want stationarity which imposes restrictions on the $\\theta$s, for:\n",
    "<ul>\n",
    "    <li>MA(1), $-1 < \\theta_1 < 1$,</li>\n",
    "    <li>MA(2), $-1 < \\theta_2 < 1, \\ \\theta_1 + \\theta_2 > -1, \\ \\theta_2 - \\theta_1 < 1$.</li>\n",
    "</ul>\n",
    "For higher order models there are more complex restrictions, but again `statsmodels` will handle those for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to Learn ARIMA.\n",
    "\n",
    "## Non-Seasonal AutoRegressive Integrated Moving Average (ARIMA) Models\n",
    "\n",
    "Now we put differencing, AutoRegressive models, and Moving Average Models together.\n",
    "\n",
    "Let $y_t$ be the original time series and $y_t'$ be a differenced version of the time series in which we have performed first differencing $d$ times. Then an ARIMA($p,d,q$) model is:\n",
    "$$\n",
    "y_t' = c + \\phi_1 y_{t-1}' + \\dots + \\phi_p y_{t-p}' + \\theta_1 \\epsilon_{t-1} + \\dots + \\theta_q \\epsilon_{t-q} + \\epsilon_t.\n",
    "$$\n",
    "\n",
    "Some special versions of the ARIMA model are listed below:\n",
    "$$\n",
    "\\begin{array}{l l}\n",
    "    \\text{White Noise} & \\text{ARIMA}(0,0,0),\\\\\n",
    "    \\text{Random Walk} & \\text{ARIMA}(0,1,0) \\text{ with no constant},\\\\\n",
    "    \\text{Random Walk with Drift} & \\text{ARIMA}(0,1,0) \\text{ with a constant},\\\\\n",
    "    \\text{AR}(p) & \\text{ARIMA}(p,0,0),\\\\\n",
    "    \\text{MA}(q) & \\text{ARIMA}(0,0,q).\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We'll now use `statsmodels` to fit and forecast the lynx data with an ARIMA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lynx_train = lynx.loc[lynx.year < datetime(1925,1,1),].copy()\n",
    "lynx_test = lynx.drop(lynx_train.index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(lynx_train.year, lynx_train.captured)\n",
    "\n",
    "plt.xlabel(\"Date\", fontsize=16)\n",
    "plt.ylabel(\"Lynx Captured\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ARIMA object\n",
    "from statsmodels.tsa.api import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First put in the training values\n",
    "# then enter the order as (p,d,q)\n",
    "arima = ARIMA(lynx_train.captured.values, order = (1,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "arima_fit = arima.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the forecast\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# the training data and fitted values\n",
    "plt.plot(lynx_train.year, lynx_train.captured,\n",
    "             'b', label = \"Training Data\")\n",
    "plt.plot(lynx_train.year,arima_fit.fittedvalues,\n",
    "             'r', label = \"Fitted Values\")\n",
    "\n",
    "# The test data and forecast\n",
    "plt.plot(lynx_test.year,lynx_test.captured,\n",
    "             'b--', label=\"Test Data\")\n",
    "plt.plot(lynx_test.year,arima_fit.forecast(len(lynx_test.captured))[0],\n",
    "             'r--', label = \"Forecast\")\n",
    "\n",
    "plt.xlabel(\"Year\", fontsize = 16)\n",
    "plt.ylabel(\"Lynx Captured\", fontsize = 16)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose $d=0$ because as we stated above the lynx data was already stationary. I chose $p=q=1$ because I just wanted to demonstrate the process of fitting the model. It is possible to get a better fit to the test data. For example try $p=4$ and $q=3$.\n",
    "\n",
    "A quick note about the `forecast()` output. Notice how unlike the exponential smoothing code I had `[0]` after `forecast()`. This is because the `.fit()` method returns an `ARIMAResults` object. When you use the `forecast()` method for this object it returns three outputs, the forecasts stored in position `0`, the standard errors on those forecasts in position `1`, and a confidence interval around your forecast in `2`. The confidence interval is similar to what we produced for the regression line in Regression Notebook 2.\n",
    "\n",
    "## Practice\n",
    "\n",
    "Now you go ahead and implement an ARIMA model on the Google Closing Price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for this notebook and for Time Series in general.\n",
    "\n",
    "We didn't dive nearly as far into the time series theory as we did for regression. That's okay these notebooks were supposed to introduce you to the topic and get you familiar with implementing the algorithms we've presented in python.\n",
    "\n",
    "To learn more flip through <a href=\"https://otexts.com/fpp2/\">Forecasting: Principles and Practice</a>, by Rob J Hyndman and George Athanasopoulos, or look through other texts and papers on this subject.\n",
    "\n",
    "There's also some additional material in the Time Series HW that you can work through.\n",
    "\n",
    "Next up Classification!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Sections 8.1 to 8.5 of <a href=\"https://otexts.com/fpp2/\">Forecasting: Principles and Practice</a>, by Rob J Hyndman and George Athanasopoulos.\n",
    "\n",
    "The time series section of the `statsmodels` documentation, <a href=\"https://www.statsmodels.org/stable/tsa.html\">https://www.statsmodels.org/stable/tsa.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
