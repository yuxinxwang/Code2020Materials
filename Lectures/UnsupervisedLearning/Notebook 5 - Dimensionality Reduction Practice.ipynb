{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction Practice\n",
    "\n",
    "We'll now have you work through practice problems using the dimensionality reduction techniques discussed in class.\n",
    "\n",
    "We'll first work with the MNIST data set. Then we turn to a new data set with images of famous faces. The goal of this notebook is to get you familiar with the different techniques we've reviewed as well as introduce how they can be used for image based data. This is not to say that these techniques are the optimal approach for image based problems, but they can be useful.\n",
    "\n",
    "## What You'll Accomplish\n",
    "\n",
    "<ul>\n",
    "    <li>You'll work through some problems with the MNIST data,</li>\n",
    "    <li>Then you'll see how you can apply techniques to help with images of people.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data\n",
    "\n",
    "We return to the MNIST data set. Again attempt to load the dataset with the higher resolution images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = pd.read_csv(\"https://raw.githubusercontent.com/cerndb/dist-keras/master/examples/data/mnist.csv\")\n",
    "\n",
    "X = np.array(nums.iloc[:,1:])\n",
    "y = np.array(nums.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remember what the data looks like\n",
    "fig,ax = plt.subplots(5,2,figsize=(16,40))\n",
    "\n",
    "for i in range(10):\n",
    "    ax[i//2,i%2].imshow(X[i,:].reshape(28, 28), cmap='gray_r')\n",
    "    ax[i//2,i%2].text(1,1,str(y[i]),fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now while these aren't super high resolution photos, $28\\times28=784$ features is still a lot. It is thus desirable to reduce the data to look for patterns.\n",
    "\n",
    "First however we will make a smaller subset because having $42,000$ observations can make the manifold methods incredibly slow.\n",
    "\n",
    "We'll randomly sample $2000$ of them, stratifying of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2,X3,y2,y3 = train_test_split(X,y,train_size = 2000, shuffle = True, random_state=440, stratify=y)\n",
    "\n",
    "# we won't need these\n",
    "del X3,y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now its your turn to work!\n",
    "\n",
    "We'll start with PCA.\n",
    "\n",
    "### PCA\n",
    "\n",
    "There is a lot of white space in our images. This indicates that we may be able to get away without needing all of the features.\n",
    "\n",
    "Look at the explained variance ratio. What seems like a good number of dimensions to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now actually run `X2` through PCA. Plot the first two components coloring the dots by their actual digit. Does it look like PCA does a good job of separating the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So PCA doesn't do a great job of separating the data, at least with 2 dimensions. \n",
    "\n",
    "### Manifold Learning\n",
    "\n",
    "Go ahead and try Isomap and tSNE and see if they perform a better job of identifying the different digits. Note do not perform local linear embeddings since they don't scale well with high dimensional data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tSNE first\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Isomap\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did one technique work better for visualization? If so which one?\n",
    "\n",
    "#### Isomap to Examine a Single Digit\n",
    "\n",
    "This next bit is adapted from this excerpt <a href=\"https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html\">https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html</a> from <a href=\"http://shop.oreilly.com/product/0636920034919.do\">Python Data Science</a>.\n",
    "\n",
    "While tSNE is better for visualizing the groups of the data set, Isomap is useful for detecting patterns in the ways we draw a certain digit.\n",
    "\n",
    "Read through this next section to see how.\n",
    "\n",
    "\n",
    "First go ahead and choose your favorite integer from $0$-$9$.\n",
    "\n",
    "We'll then take $1/5$ of all instances of that integer from the original data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your favorite integer from 0-9\n",
    "# the default is 2\n",
    "choice = 2\n",
    "\n",
    "# Choose 1/5 of the \"4\" digits to project from the original\n",
    "# data set\n",
    "subset = X[y == choice][::5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now use the most simple isomap the one with two components and all the `sklearn` defaults. We'll use this model to project our `subset` into two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this simple isomap\n",
    "iso = Isomap(n_components = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is taken from the excerpt. It takes in the `subset` and `iso` and outputs the 2D projection along with a number of the handwritten digits. This will allow you to identify any differences in the style of numbers assigned to each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from excerpt\n",
    "from matplotlib import offsetbox\n",
    "\n",
    "def plot_components(data, model, images=None, ax=None,\n",
    "                    thumb_frac=0.05, cmap='gray'):\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    proj = model.fit_transform(data)\n",
    "    ax.scatter(proj[:, 0], proj[:, 1], c='b')\n",
    "    \n",
    "    if images is not None:\n",
    "        min_dist_2 = (thumb_frac * max(proj.max(0) - proj.min(0))) ** 2\n",
    "        shown_images = np.array([2 * proj.max(0)])\n",
    "        for i in range(data.shape[0]):\n",
    "            dist = np.sum((proj[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < min_dist_2:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.vstack([shown_images, proj[i]])\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(images[i], cmap=cmap),\n",
    "                                      proj[i])\n",
    "            ax.add_artist(imagebox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following chunk makes the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 14))\n",
    "\n",
    "plot_components(subset, iso, images=subset.reshape((-1, 28, 28)),\n",
    "                ax=ax, thumb_frac=0.05, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice? Are there any patterns or commonalities in the different regions of the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faceoff!\n",
    "\n",
    "We'll now introduce another common database, the labeled faces in the Wild dataset, <a href=\"http://vis-www.cs.umass.edu/lfw/\">http://vis-www.cs.umass.edu/lfw/</a>. \n",
    "\n",
    "Before conitnuing I note that this portion of the notebook is inspired by the previous excerpt <a hef=\"https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html\">https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html</a> and Chapter 3 of the book <a href=\"https://www.amazon.com/Introduction-Machine-Learning-Python-Scientists/dp/1449369413\">https://www.amazon.com/Introduction-Machine-Learning-Python-Scientists/dp/1449369413</a>.\n",
    "\n",
    "Let's first get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this can take a long time.\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "people = fetch_lfw_people(min_faces_per_person=20, resize=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code from Chapter 3\n",
    "image_shape = people.images[0].shape\n",
    "fig, ax = plt.subplots(2,5, figsize=(15,8),\n",
    "                      subplot_kw = {'xticks':(),'yticks':()})\n",
    "\n",
    "for target, image, ax in zip(people.target, people.images, ax.ravel()):\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(people.target_names[target])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code from Chapter 3\n",
    "# We first clean the data set to be more balanced\n",
    "# see how many of each person we have:\n",
    "counts = np.bincount(people.target)\n",
    "for i, (count,name) in enumerate(zip(counts,people.target_names)):\n",
    "    print(name,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code from Chapter 3\n",
    "# We limit each person to 50 photos to make the data more\n",
    "# balanced\n",
    "# make an index of observations to keep\n",
    "mask = np.zeros(people.target.shape, dtype=np.bool)\n",
    "\n",
    "for target in np.unique(people.target):\n",
    "    mask[np.where(people.target == target)[0][:50]] = 1\n",
    "    \n",
    "X_people = people.data[mask]\n",
    "y_people = people.target[mask]\n",
    "\n",
    "# We now scale the the data\n",
    "X_people = X_people/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images did we start with?\n",
    "np.shape(people.data)\n",
    "\n",
    "# 3023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images did we end with?\n",
    "np.shape(X_people)\n",
    "\n",
    "# 2063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code from Chapter 3\n",
    "# See each person has at most 50 pics now\n",
    "counts = np.bincount(y_people)\n",
    "for i, (count,name) in enumerate(zip(counts,people.target_names)):\n",
    "    print(name,count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that that data is cleaner we can get to work!\n",
    "\n",
    "### PCA \n",
    "\n",
    "You may wish to build a classifier that can detect the person present in a newly entered image, ahem Facebook and Instagram ahem, but as you might imagine this is an incredibly difficult problem.\n",
    "\n",
    "Let's try something stupid. Build a $1$ Nearest Neighbors classifier, i.e. a nearest neighbors classifier with $k$ set to $1$. Then calculate the test set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now put the features through PCA, keep $100$ components, and refit your silly $1$ nearest neighbor model. How does the test accuracy compare to the last model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "## label your PCA model pca\n",
    "\n",
    "\n",
    "## store the transformed images in X_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It probably still isn't great, but it should be an improvement over the last model.\n",
    "\n",
    "Let's now see how we might try to reconstruct the faces using the components from PCA.\n",
    "\n",
    "We return to the component vectors of the PCA output, remember you can get these using `pca.components_`, assuming your PCA model was stored in `pca`.\n",
    "\n",
    "Run through the following code chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the shape of the component vectors?\n",
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code from chapter 3\n",
    "\n",
    "# We can plot these vectors to see what features\n",
    "# of the faces the vectors are capturing\n",
    "# we look at the first 20 components\n",
    "fig, axes = plt.subplots(4,5, figsize = (15,20))\n",
    "\n",
    "for i, (component, ax) in enumerate(zip(pca.components_, axes.ravel())):\n",
    "    ax.imshow(component.reshape(87,65))\n",
    "    ax.set_title(\"component \" + str(i), fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than being nightmare fuel, what do you notice aboute each of the components. What does it seem like each component is capturing?\n",
    "\n",
    "\n",
    "\n",
    "When you're ready to move on let's look at a specific face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll look at the governator\n",
    "# Former Mr. Universe, Arnold Schwarzenegger\n",
    "fig, ax = plt.subplots(1,1, figsize = (8,6))\n",
    "\n",
    "ax.imshow(X_people[y_people==6][0].reshape(87,65))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of this face as being a linear combination of the pca component vectors.\n",
    "\n",
    "If we let $a_1,a_2,\\dots$ as being the pca values for this image, and $w_1,w_2,w_3,\\dots$ as being the component vectors then we can think of the image as:\n",
    "$$\n",
    "a = a_1 w_1 + a_2 w_2 + a_3 w_3 + \\dots \n",
    "$$\n",
    "\n",
    "Let's visualize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I make a new PCA that has\n",
    "# 2000 components\n",
    "pca = PCA(2000)\n",
    "\n",
    "X_pca = pca.fit_transform(X_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,3,figsize=(20,20))\n",
    "\n",
    "arnie_pca = X_pca[y_people==6][0]\n",
    "\n",
    "# og image\n",
    "ax[0,0].set_title(\"Original Image\", fontsize=14)\n",
    "ax[0,0].imshow(X_people[y_people==6][0].reshape(87,65))\n",
    "\n",
    "# 10 comps\n",
    "ax[0,1].set_title(\"10 Components\", fontsize=14)\n",
    "arnie_10 = pca.components_.transpose()[:,:10].dot(arnie_pca[:10].transpose())\n",
    "ax[0,1].imshow(arnie_10.reshape(87,65))\n",
    "\n",
    "# 50 comps\n",
    "ax[0,2].set_title(\"50 Components\", fontsize=14)\n",
    "arnie_50 = pca.components_.transpose()[:,:50].dot(arnie_pca[:50].transpose())\n",
    "ax[0,2].imshow(arnie_50.reshape(87,65))\n",
    "\n",
    "# 100 comps\n",
    "ax[1,0].set_title(\"100 Components\", fontsize=14)\n",
    "arnie_100 = pca.components_.transpose()[:,:100].dot(arnie_pca[:100].transpose())\n",
    "ax[1,0].imshow(arnie_100.reshape(87,65))\n",
    "\n",
    "# 500 comps\n",
    "ax[1,1].set_title(\"500 Components\", fontsize=14)\n",
    "arnie_500 = pca.components_.transpose()[:,:500].dot(arnie_pca[:500].transpose())\n",
    "ax[1,1].imshow(arnie_500.reshape(87,65))\n",
    "\n",
    "# 750 comps\n",
    "ax[1,2].set_title(\"750 Components\", fontsize=14)\n",
    "arnie_750 = pca.components_.transpose()[:,:750].dot(arnie_pca[:750].transpose())\n",
    "ax[1,2].imshow(arnie_750.reshape(87,65))\n",
    "\n",
    "# 1000 comps\n",
    "ax[2,0].set_title(\"1000 Components\", fontsize=14)\n",
    "arnie_1000 = pca.components_.transpose()[:,:1000].dot(arnie_pca[:1000].transpose())\n",
    "ax[2,0].imshow(arnie_1000.reshape(87,65))\n",
    "\n",
    "\n",
    "# 1500 comps\n",
    "ax[2,1].set_title(\"1500 Components\", fontsize=14)\n",
    "arnie_1500 = pca.components_.transpose()[:,:1500].dot(arnie_pca[:1500].transpose())\n",
    "ax[2,1].imshow(arnie_1500.reshape(87,65))\n",
    "\n",
    "\n",
    "# 2000 comps\n",
    "ax[2,2].set_title(\"2000 Components\", fontsize=14)\n",
    "arnie_2000 = pca.components_.transpose()[:,:2000].dot(arnie_pca[:2000].transpose())\n",
    "ax[2,2].imshow(arnie_2000.reshape(87,65))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now choose your own image to decompose using PCA. Go through this same procedure with your image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retention of the original image is the result of capturing more and more of the variance in the original data set with PCA. You may remember that we have a way to measure how much of the original variance of the data set PCA captures.\n",
    "\n",
    "Implement that below and see how many components are needed to retain $90\\%$ of the variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While PCA was useful we should now see that we still need a somewhat large number of features to retain enough information to be useful.\n",
    "\n",
    "### Manifold Learning\n",
    "\n",
    "We may have shortsold PCA we are able to retain reasonable information with $100$ or so components, remember we started with $5655$-dimensional data, so we made a significant decrease in the dimensionality of our data. However as humans we are still limited to 2 or 3 dimensions in terms of visualizing data.\n",
    "\n",
    "Let's see if our manifold learning techniques can help with 2d visualizations of our data to look for patterns in the data.\n",
    "\n",
    "As a note the PCA subsection was mostly drawing from Chapter 3 of the book <a href=\"https://www.amazon.com/Introduction-Machine-Learning-Python-Scientists/dp/1449369413\">https://www.amazon.com/Introduction-Machine-Learning-Python-Scientists/dp/1449369413</a>, the following draws from <a hef=\"https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html\">https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html</a>.\n",
    "\n",
    "#### tSNE\n",
    "\n",
    "See if tSNE is able to capture clusters in the data, first run the entirety of `X_people` through tSNE then plot the results. When you are done with that select $5$-$10$ people and subset `X_people` to only include them. Then run the subset through tSNE.\n",
    "\n",
    "How does tSNE perform is the 2D representation of the data useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isomap\n",
    "\n",
    "Make a simple isomap model with 2 components.\n",
    "\n",
    "Use the previous `plot_components` function with a subset of the data. Does isomap detect patterns in the data? What do you observe with the face images and their placement in the 2D projection from isomap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's All for Unsupervised Learning!\n",
    "\n",
    "Hopefully this notebook allowed you to get more comfortable with dimesionality reduction. It is a very interesting field and can be useful in your projects both for the course and on your own.\n",
    "\n",
    "Next we end the course with a very brief introduction to neural nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
